{
    "patch": "diff --git a/pygments/formatters/latex.py b/pygments/formatters/latex.py\nindex 2f7971e8..530235d7 100644\n--- a/pygments/formatters/latex.py\n+++ b/pygments/formatters/latex.py\n@@ -282,11 +282,23 @@ class LatexFormatter(Formatter):\n         cp = self.commandprefix\n \n         def rgbcolor(col):\n-            if col:\n-                return ','.join(['%.2f' % (int(col[i] + col[i + 1], 16) / 255.0)\n-                                 for i in (0, 2, 4)])\n-            else:\n-                return '1,1,1'\n+            \"\"\"\n+            Convert a CSS-style hex color (RRGGBB) into LaTeX rgb components.\n+\n+            The LaTeX color package expects values in the range 0..1.\n+            \"\"\"\n+            if not col:\n+                return '0,0,0'\n+            # Be forgiving if a leading '#' is present.\n+            if col[0] == '#':\n+                col = col[1:]\n+            if len(col) != 6:\n+                return '0,0,0'\n+            try:\n+                return ','.join('%.2f' % (int(col[i:i+2], 16) / 255.0)\n+                                for i in (0, 2, 4))\n+            except ValueError:\n+                return '0,0,0'\n \n         for ttype, ndef in self.style:\n             name = _get_ttype_name(ttype)\n@@ -452,8 +464,6 @@ class LatexEmbeddedLexer(Lexer):\n         Lexer.__init__(self, **options)\n \n     def get_tokens_unprocessed(self, text):\n-        # find and remove all the escape tokens (replace with an empty string)\n-        # this is very similar to DelegatingLexer.get_tokens_unprocessed.\n         buffered = ''\n         insertions = []\n         insertion_buf = []\n@@ -469,21 +479,22 @@ class LatexEmbeddedLexer(Lexer):\n             insertions.append((len(buffered), insertion_buf))\n         return do_insertions(insertions,\n                              self.lang.get_tokens_unprocessed(buffered))\n-\n     def _find_safe_escape_tokens(self, text):\n-        \"\"\" find escape tokens that are not in strings or comments \"\"\"\n+        \"\"\"Find escape tokens that are not in strings or comments.\"\"\"\n         for i, t, v in self._filter_to(\n             self.lang.get_tokens_unprocessed(text),\n             lambda t: t in Token.Comment or t in Token.String\n         ):\n             if t is None:\n+                # v is safe to scan for embedded LaTeX segments\n                 for i2, t2, v2 in self._find_escape_tokens(v):\n-                    yield i + i2, t2, v2\n+                    yield i2, t2, v2\n             else:\n-                yield i, None, v\n+                # strings/comments are passed through unchanged\n+                yield i, t, v\n \n     def _filter_to(self, it, pred):\n-        \"\"\" Keep only the tokens that match `pred`, merge the others together \"\"\"\n+        \"\"\"Keep only the tokens that match `pred`, merge the others together.\"\"\"\n         buf = ''\n         idx = 0\n         for i, t, v in it:\n@@ -500,7 +511,7 @@ class LatexEmbeddedLexer(Lexer):\n             yield idx, None, buf\n \n     def _find_escape_tokens(self, text):\n-        \"\"\" Find escape tokens within text, give token=None otherwise \"\"\"\n+        \"\"\"Find escape tokens within text, give token=None otherwise.\"\"\"\n         index = 0\n         while text:\n             a, sep1, text = text.partition(self.left)\n",
    "success": false,
    "steps": 30,
    "estimated_tokens": 21121
}