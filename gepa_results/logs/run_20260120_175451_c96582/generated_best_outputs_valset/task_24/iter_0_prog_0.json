{
    "patch": "diff --git a/pygments/lexer.py b/pygments/lexer.py\nindex 3061964a..16b79a27 100644\n--- a/pygments/lexer.py\n+++ b/pygments/lexer.py\n@@ -236,17 +236,32 @@ class Lexer(metaclass=LexerMeta):\n             if text.startswith('\\ufeff'):\n                 text = text[len('\\ufeff'):]\n \n-        # text now *is* a unicode string\n-        text = text.replace('\\r\\n', '\\n')\n-        text = text.replace('\\r', '\\n')\n+        # NOTE: Do not normalize newlines here.\n+        #\n+        # Lexers should be able to round-trip their input, i.e. concatenating\n+        # token values should reproduce the original input exactly. Normalizing\n+        # '\\r\\n' / '\\r' to '\\n' breaks that expectation and also makes\n+        # `ensurenl` ambiguous about which line ending to append.\n         if self.stripall:\n             text = text.strip()\n         elif self.stripnl:\n-            text = text.strip('\\n')\n+            # Strip all common newline characters from both ends.\n+            text = text.strip('\\r\\n')\n+\n+        # Expand tabs only if explicitly enabled with a positive tab size.\n+        # Historically Pygments used a +1 hack which caused tabsize=0 to change\n+        # the input; tabsize=0 must not expand tabs.\n         if self.tabsize > 0:\n             text = text.expandtabs(self.tabsize)\n-        if self.ensurenl and not text.endswith('\\n'):\n-            text += '\\n'\n+\n+        if self.ensurenl and not text.endswith(('\\n', '\\r')):\n+            # Preserve newline style when appending a final newline.\n+            if '\\r\\n' in text:\n+                text += '\\r\\n'\n+            elif '\\r' in text:\n+                text += '\\r'\n+            else:\n+                text += '\\n'\n \n         return text\n \n",
    "success": false,
    "steps": 30,
    "estimated_tokens": 25844
}