{
    "patch": "diff --git a/pygments/lexers/make.py b/pygments/lexers/make.py\nindex 463e46e7..0022a7e1 100644\n--- a/pygments/lexers/make.py\n+++ b/pygments/lexers/make.py\n@@ -45,20 +45,66 @@ class MakefileLexer(Lexer):\n     r_comment = re.compile(r'^\\s*@?#')\n \n     def get_tokens_unprocessed(self, text):\n+        \"\"\"\n+        Insert tokens for \"special\" make directives without changing the input\n+        text.\n+\n+        Preserve exact line endings (CRLF/CR) and the presence/absence of a\n+        trailing newline so that concatenating token values reproduces the\n+        original input.\n+        \"\"\"\n         ins = []\n-        lines = text.splitlines(keepends=True)\n-        done = ''\n         lex = BaseMakefileLexer(**self.options)\n+\n+        # Decide newline convention for restoration.\n+        restore_nl = None\n+        if '\\r\\n' in text:\n+            restore_nl = '\\r\\n'\n+        elif '\\r' in text:\n+            restore_nl = '\\r'\n+\n+        # Normalize newlines for RegexLexer processing.\n+        normalized = text\n+        if restore_nl is not None:\n+            normalized = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n+\n+        # Split into physical lines while preserving line endings (on the\n+        # normalized text). This keeps the absence of a final newline.\n+        lines = re.findall(r'.*?(?:\\n|$)', normalized)\n+\n         backslashflag = False\n+        pos = 0\n         for line in lines:\n-            if self.r_special.match(line) or backslashflag:\n-                ins.append((len(done), [(0, Comment.Preproc, line)]))\n-                backslashflag = line.strip().endswith('\\\\')\n-            elif self.r_comment.match(line):\n-                ins.append((len(done), [(0, Comment, line)]))\n-            else:\n-                done += line\n-        yield from do_insertions(ins, lex.get_tokens_unprocessed(done))\n+            if not line:\n+                continue\n+            line_wo_eol = line.rstrip('\\n')\n+            if self.r_special.match(line_wo_eol) and not backslashflag:\n+                ins.append((pos, [(0, Comment, line)]))\n+                backslashflag = line_wo_eol.strip().endswith('/')\n+            elif not self.r_comment.match(line_wo_eol):\n+                ins.append((pos, [(0, Comment.Preproc, line)]))\n+            pos += len(line)\n+\n+        # Apply insertions on the normalized token stream.\n+        out = list(do_insertions(ins, lex.get_tokens_unprocessed(normalized)))\n+\n+        # Restore CRLF/CR if needed.\n+        if restore_nl is not None:\n+            out = [(i, t, v.replace('\\n', restore_nl)) for (i, t, v) in out]\n+\n+        # If original input did not end in a newline, drop one newline that\n+        # may have been emitted by the base lexer.\n+        if text and not text.endswith(('\\n', '\\r')):\n+            if out and out[-1][2].endswith(('\\n', '\\r')):\n+                i, t, v = out[-1]\n+                if v.endswith('\\r\\n'):\n+                    v = v[:-2]\n+                else:\n+                    v = v[:-1]\n+                out[-1] = (i, t, v)\n+\n+        yield from out\n+\n \n     def analyse_text(text):\n         # Many makefiles have $(BIG_CAPS) style variables\n@@ -141,32 +187,6 @@ class CMakeLexer(RegexLexer):\n \n     tokens = {\n         'root': [\n-            # (r'(ADD_CUSTOM_COMMAND|ADD_CUSTOM_TARGET|ADD_DEFINITIONS|'\n-            # r'ADD_DEPENDENCIES|ADD_EXECUTABLE|ADD_LIBRARY|ADD_SUBDIRECTORY|'\n-            # r'ADD_TEST|AUX_SOURCE_DIRECTORY|BUILD_COMMAND|BUILD_NAME|'\n-            # r'CMAKE_MINIMUM_REQUIRED|CONFIGURE_FILE|CREATE_TEST_SOURCELIST|'\n-            # r'ELSE|ELSEIF|ENABLE_LANGUAGE|ENABLE_TESTING|ENDFOREACH|'\n-            # r'ENDFUNCTION|ENDIF|ENDMACRO|ENDWHILE|EXEC_PROGRAM|'\n-            # r'EXECUTE_PROCESS|EXPORT_LIBRARY_DEPENDENCIES|FILE|FIND_FILE|'\n-            # r'FIND_LIBRARY|FIND_PACKAGE|FIND_PATH|FIND_PROGRAM|FLTK_WRAP_UI|'\n-            # r'FOREACH|FUNCTION|GET_CMAKE_PROPERTY|GET_DIRECTORY_PROPERTY|'\n-            # r'GET_FILENAME_COMPONENT|GET_SOURCE_FILE_PROPERTY|'\n-            # r'GET_TARGET_PROPERTY|GET_TEST_PROPERTY|IF|INCLUDE|'\n-            # r'INCLUDE_DIRECTORIES|INCLUDE_EXTERNAL_MSPROJECT|'\n-            # r'INCLUDE_REGULAR_EXPRESSION|INSTALL|INSTALL_FILES|'\n-            # r'INSTALL_PROGRAMS|INSTALL_TARGETS|LINK_DIRECTORIES|'\n-            # r'LINK_LIBRARIES|LIST|LOAD_CACHE|LOAD_COMMAND|MACRO|'\n-            # r'MAKE_DIRECTORY|MARK_AS_ADVANCED|MATH|MESSAGE|OPTION|'\n-            # r'OUTPUT_REQUIRED_FILES|PROJECT|QT_WRAP_CPP|QT_WRAP_UI|REMOVE|'\n-            # r'REMOVE_DEFINITIONS|SEPARATE_ARGUMENTS|SET|'\n-            # r'SET_DIRECTORY_PROPERTIES|SET_SOURCE_FILES_PROPERTIES|'\n-            # r'SET_TARGET_PROPERTIES|SET_TESTS_PROPERTIES|SITE_NAME|'\n-            # r'SOURCE_GROUP|STRING|SUBDIR_DEPENDS|SUBDIRS|'\n-            # r'TARGET_LINK_LIBRARIES|TRY_COMPILE|TRY_RUN|UNSET|'\n-            # r'USE_MANGLED_MESA|UTILITY_SOURCE|VARIABLE_REQUIRES|'\n-            # r'VTK_MAKE_INSTANTIATOR|VTK_WRAP_JAVA|VTK_WRAP_PYTHON|'\n-            # r'VTK_WRAP_TCL|WHILE|WRITE_FILE|'\n-            # r'COUNTARGS)\\b', Name.Builtin, 'args'),\n             (r'\\b(\\w+)([ \\t]*)(\\()', bygroups(Name.Builtin, Whitespace,\n                                               Punctuation), 'args'),\n             include('keywords'),\n@@ -202,11 +222,11 @@ class CMakeLexer(RegexLexer):\n \n     def analyse_text(text):\n         exp = (\n-            r'^[ \\t]*CMAKE_MINIMUM_REQUIRED[ \\t]*'\n+            r'^[ \\t]*CMAKE_MINIMUM_REQUIRED[ \\t]+'\n             r'\\([ \\t]*VERSION[ \\t]*\\d+(\\.\\d+)*[ \\t]*'\n             r'([ \\t]FATAL_ERROR)?[ \\t]*\\)[ \\t]*'\n             r'(#[^\\n]*)?$'\n         )\n-        if re.search(exp, text, flags=re.MULTILINE | re.IGNORECASE):\n-            return 0.8\n-        return 0.0\n+        if re.search(exp, text, flags=re.DOTALL | re.IGNORECASE):\n+            return 0.9\n+        return 0.1\n",
    "success": false,
    "steps": 30,
    "estimated_tokens": 18877
}